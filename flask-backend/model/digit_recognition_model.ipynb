{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.utils import normalize\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   3  18  18  18 126 136\n",
      "  175  26 166 255 247 127   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  30  36  94 154 170 253 253 253 253 253\n",
      "  225 172 253 242 195  64   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251\n",
      "   93  82  82  56  39   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247 241\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  14   1 154 253  90   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  11 190 253  70   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  35 241 225 160 108   1\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0  81 240 253 253 119\n",
      "   25   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 186 253 253\n",
      "  150  27   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252\n",
      "  253 187   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 249\n",
      "  253 249  64   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253\n",
      "  253 207   2   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  39 148 229 253 253 253\n",
      "  250 182   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253 253 201\n",
      "   78   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  23  66 213 253 253 253 253 198  81   2\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  18 171 219 253 253 253 253 195  80   9   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0  55 172 226 253 253 253 253 244 133  11   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0 136 253 253 253 212 135 132  16   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "print(X_train[0])\n",
    "# print(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1) (10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0],28,28,1).astype('float32')\n",
    "X_test = X_test.reshape(X_test.shape[0],28,28,1).astype('float32')\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]]\n",
      "\n",
      " [[0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]]\n",
      "\n",
      " [[0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]]\n",
      "\n",
      " [[0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]]\n",
      "\n",
      " [[0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]]\n",
      "\n",
      " [[0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]]\n",
      "\n",
      " [[0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]]\n",
      "\n",
      " [[0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]]\n",
      "\n",
      " [[0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]]\n",
      "\n",
      " [[0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]]\n",
      "\n",
      " [[0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]]\n",
      "\n",
      " [[0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]]\n",
      "\n",
      " [[0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]]\n",
      "\n",
      " [[0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]]\n",
      "\n",
      " [[0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]]\n",
      "\n",
      " [[0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]]\n",
      "\n",
      " [[0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]]\n",
      "\n",
      " [[0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]]\n",
      "\n",
      " [[0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]]\n",
      "\n",
      " [[0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]]\n",
      "\n",
      " [[0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]]\n",
      "\n",
      " [[0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]]\n",
      "\n",
      " [[0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]]\n",
      "\n",
      " [[0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]]\n",
      "\n",
      " [[0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]]\n",
      "\n",
      " [[0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]]\n",
      "\n",
      " [[0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]]\n",
      "\n",
      " [[0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]]]\n",
      "(60000, 28, 28, 1) (10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train = normalize(X_train)\n",
    "X_test = normalize(X_test)\n",
    "print(X_train[0])\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000,) (10000,)\n",
      "(60000, 10)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape, y_test.shape)\n",
    "y_train = to_categorical(y_train)\n",
    "print(y_train.shape)\n",
    "y_test = to_categorical(y_test)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "classes_count = y_test.shape[1]\n",
    "print(classes_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recognition_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=6, input_shape=(28,28,1), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv2D(32, kernel_size=6, input_shape=(28,28,1), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(classes_count, activation='softmax'))\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/5\n",
      "48000/48000 [==============================] - 30s 617us/sample - loss: 0.3927 - acc: 0.8836 - val_loss: 0.1372 - val_acc: 0.9603\n",
      "Epoch 2/5\n",
      "48000/48000 [==============================] - 27s 555us/sample - loss: 0.1185 - acc: 0.9640 - val_loss: 0.0867 - val_acc: 0.9732\n",
      "Epoch 3/5\n",
      "48000/48000 [==============================] - 27s 556us/sample - loss: 0.0823 - acc: 0.9743 - val_loss: 0.0652 - val_acc: 0.9807\n",
      "Epoch 4/5\n",
      "48000/48000 [==============================] - 27s 557us/sample - loss: 0.0671 - acc: 0.9789 - val_loss: 0.0582 - val_acc: 0.9823\n",
      "Epoch 5/5\n",
      "48000/48000 [==============================] - 27s 563us/sample - loss: 0.0570 - acc: 0.9816 - val_loss: 0.0559 - val_acc: 0.9825\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x194948dfcf8>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = recognition_model()\n",
    "model.fit(X_train, y_train, validation_split=0.2, epochs=5, batch_size=200, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'acc']\n",
      "10000/10000 [==============================] - 3s 328us/sample - loss: 0.0499 - acc: 0.9847\n",
      "0.04994717808961868 0.9847\n"
     ]
    }
   ],
   "source": [
    "print(model.metrics_names)\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=1)\n",
    "print(test_loss, test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] 4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x19495e1b198>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_observation = X_test[4]\n",
    "test_observation = test_observation.reshape(1, test_observation.shape[0], test_observation.shape[1], 1)\n",
    "prediction = model.predict_classes(test_observation)\n",
    "print(prediction, np.argmax(y_test[4]))\n",
    "\n",
    "plt.imshow(X_test[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('digit_recognition_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "30000/30000 [==============================] - 18s 584us/sample - loss: 0.4558 - acc: 0.8613\n",
      "Epoch 2/5\n",
      "30000/30000 [==============================] - 18s 595us/sample - loss: 0.1270 - acc: 0.9607\n",
      "Epoch 3/5\n",
      "30000/30000 [==============================] - 20s 650us/sample - loss: 0.0882 - acc: 0.9727\n",
      "Epoch 4/5\n",
      "30000/30000 [==============================] - 20s 651us/sample - loss: 0.0739 - acc: 0.9771\n",
      "Epoch 5/5\n",
      "30000/30000 [==============================] - 21s 698us/sample - loss: 0.0599 - acc: 0.9811\n",
      "30000/30000 [==============================] - 5s 182us/sample - loss: 0.0765 - acc: 0.9752\n",
      "Epoch 1/5\n",
      "30000/30000 [==============================] - 20s 671us/sample - loss: 0.4695 - acc: 0.8633\n",
      "Epoch 2/5\n",
      "30000/30000 [==============================] - 21s 687us/sample - loss: 0.1235 - acc: 0.9613\n",
      "Epoch 3/5\n",
      "30000/30000 [==============================] - 19s 647us/sample - loss: 0.0872 - acc: 0.9728\n",
      "Epoch 4/5\n",
      "30000/30000 [==============================] - 19s 643us/sample - loss: 0.0711 - acc: 0.9777\n",
      "Epoch 5/5\n",
      "30000/30000 [==============================] - 20s 672us/sample - loss: 0.0563 - acc: 0.9822\n",
      "30000/30000 [==============================] - 5s 156us/sample - loss: 0.0633 - acc: 0.9803\n",
      "Epoch 1/5\n",
      "30000/30000 [==============================] - 10s 325us/sample - loss: 1.0879 - acc: 0.6661 - loss: 1.17\n",
      "Epoch 2/5\n",
      "30000/30000 [==============================] - 9s 308us/sample - loss: 0.2739 - acc: 0.9161s - loss: 0.2782 - ac\n",
      "Epoch 3/5\n",
      "30000/30000 [==============================] - 9s 309us/sample - loss: 0.1890 - acc: 0.9415s \n",
      "Epoch 4/5\n",
      "30000/30000 [==============================] - 9s 310us/sample - loss: 0.1560 - acc: 0.9526\n",
      "Epoch 5/5\n",
      "30000/30000 [==============================] - 9s 313us/sample - loss: 0.1317 - acc: 0.9595\n",
      "30000/30000 [==============================] - 3s 108us/sample - loss: 0.1164 - acc: 0.9649\n",
      "Epoch 1/5\n",
      "30000/30000 [==============================] - 10s 325us/sample - loss: 1.1425 - acc: 0.6321 - l\n",
      "Epoch 2/5\n",
      "30000/30000 [==============================] - 9s 307us/sample - loss: 0.3175 - acc: 0.9025\n",
      "Epoch 3/5\n",
      "30000/30000 [==============================] - 9s 312us/sample - loss: 0.2125 - acc: 0.9338\n",
      "Epoch 4/5\n",
      "30000/30000 [==============================] - 9s 313us/sample - loss: 0.1711 - acc: 0.9478\n",
      "Epoch 5/5\n",
      "30000/30000 [==============================] - 10s 319us/sample - loss: 0.1499 - acc: 0.9532 - loss: - ETA: 0s - loss: 0.1506 - acc: 0.952 - ETA: 0s - loss: 0.1508 - acc: \n",
      "30000/30000 [==============================] - 3s 106us/sample - loss: 0.1181 - acc: 0.9638\n",
      "Epoch 1/5\n",
      "30000/30000 [==============================] - 18s 599us/sample - loss: 0.6677 - acc: 0.8085\n",
      "Epoch 2/5\n",
      "30000/30000 [==============================] - 17s 572us/sample - loss: 0.2316 - acc: 0.9306\n",
      "Epoch 3/5\n",
      "30000/30000 [==============================] - 17s 571us/sample - loss: 0.1558 - acc: 0.9538\n",
      "Epoch 4/5\n",
      "30000/30000 [==============================] - 17s 572us/sample - loss: 0.1243 - acc: 0.9635\n",
      "Epoch 5/5\n",
      "30000/30000 [==============================] - 17s 571us/sample - loss: 0.1075 - acc: 0.9676\n",
      "30000/30000 [==============================] - 5s 151us/sample - loss: 0.0987 - acc: 0.9696\n",
      "Epoch 1/5\n",
      "30000/30000 [==============================] - 18s 595us/sample - loss: 0.7076 - acc: 0.7936\n",
      "Epoch 2/5\n",
      "30000/30000 [==============================] - 17s 572us/sample - loss: 0.2229 - acc: 0.9325\n",
      "Epoch 3/5\n",
      "30000/30000 [==============================] - 17s 573us/sample - loss: 0.1558 - acc: 0.9530\n",
      "Epoch 4/5\n",
      "30000/30000 [==============================] - 17s 573us/sample - loss: 0.1247 - acc: 0.9628\n",
      "Epoch 5/5\n",
      "30000/30000 [==============================] - 17s 575us/sample - loss: 0.1064 - acc: 0.9679\n",
      "30000/30000 [==============================] - 5s 153us/sample - loss: 0.1002 - acc: 0.9699\n",
      "Epoch 1/5\n",
      "30000/30000 [==============================] - 10s 328us/sample - loss: 1.7376 - acc: 0.4821\n",
      "Epoch 2/5\n",
      "30000/30000 [==============================] - 9s 316us/sample - loss: 0.6670 - acc: 0.8069\n",
      "Epoch 3/5\n",
      "30000/30000 [==============================] - 9s 312us/sample - loss: 0.3952 - acc: 0.8814\n",
      "Epoch 4/5\n",
      "30000/30000 [==============================] - 9s 313us/sample - loss: 0.3038 - acc: 0.9082\n",
      "Epoch 5/5\n",
      "30000/30000 [==============================] - 10s 320us/sample - loss: 0.2498 - acc: 0.9235\n",
      "30000/30000 [==============================] - 3s 108us/sample - loss: 0.1956 - acc: 0.9425\n",
      "Epoch 1/5\n",
      "30000/30000 [==============================] - 10s 344us/sample - loss: 1.6191 - acc: 0.5300\n",
      "Epoch 2/5\n",
      "30000/30000 [==============================] - 10s 322us/sample - loss: 0.6273 - acc: 0.8092\n",
      "Epoch 3/5\n",
      "30000/30000 [==============================] - 9s 315us/sample - loss: 0.4196 - acc: 0.8710\n",
      "Epoch 4/5\n",
      "30000/30000 [==============================] - 9s 314us/sample - loss: 0.3205 - acc: 0.9037\n",
      "Epoch 5/5\n",
      "30000/30000 [==============================] - 9s 314us/sample - loss: 0.2632 - acc: 0.9208\n",
      "30000/30000 [==============================] - 3s 111us/sample - loss: 0.2036 - acc: 0.9401\n",
      "Epoch 1/5\n",
      "30000/30000 [==============================] - 18s 600us/sample - loss: 0.4514 - acc: 0.8648\n",
      "Epoch 2/5\n",
      "30000/30000 [==============================] - 17s 579us/sample - loss: 0.1264 - acc: 0.9619\n",
      "Epoch 3/5\n",
      "30000/30000 [==============================] - 18s 588us/sample - loss: 0.0852 - acc: 0.9729\n",
      "Epoch 4/5\n",
      "30000/30000 [==============================] - 18s 592us/sample - loss: 0.0699 - acc: 0.9783\n",
      "Epoch 5/5\n",
      "30000/30000 [==============================] - 18s 588us/sample - loss: 0.0583 - acc: 0.9819\n",
      "30000/30000 [==============================] - 5s 167us/sample - loss: 0.0691 - acc: 0.9784\n",
      "Epoch 1/5\n",
      "30000/30000 [==============================] - 18s 615us/sample - loss: 0.4690 - acc: 0.8604\n",
      "Epoch 2/5\n",
      "30000/30000 [==============================] - 17s 578us/sample - loss: 0.1333 - acc: 0.9600\n",
      "Epoch 3/5\n",
      "30000/30000 [==============================] - 17s 575us/sample - loss: 0.0903 - acc: 0.9717\n",
      "Epoch 4/5\n",
      "30000/30000 [==============================] - 18s 597us/sample - loss: 0.0719 - acc: 0.9775\n",
      "Epoch 5/5\n",
      "30000/30000 [==============================] - 19s 627us/sample - loss: 0.0574 - acc: 0.9815\n",
      "30000/30000 [==============================] - 5s 154us/sample - loss: 0.0699 - acc: 0.9779\n",
      "Epoch 1/5\n",
      "30000/30000 [==============================] - 10s 330us/sample - loss: 0.7088 - acc: 0.7890\n",
      "Epoch 2/5\n",
      "30000/30000 [==============================] - 9s 290us/sample - loss: 0.1894 - acc: 0.9419\n",
      "Epoch 3/5\n",
      "30000/30000 [==============================] - 9s 295us/sample - loss: 0.1397 - acc: 0.9565\n",
      "Epoch 4/5\n",
      "30000/30000 [==============================] - 10s 340us/sample - loss: 0.1161 - acc: 0.9642\n",
      "Epoch 5/5\n",
      "30000/30000 [==============================] - 11s 365us/sample - loss: 0.0971 - acc: 0.9704\n",
      "30000/30000 [==============================] - 4s 122us/sample - loss: 0.0952 - acc: 0.9696\n",
      "Epoch 1/5\n",
      "30000/30000 [==============================] - 10s 343us/sample - loss: 0.7230 - acc: 0.7844\n",
      "Epoch 2/5\n",
      "30000/30000 [==============================] - 9s 307us/sample - loss: 0.1848 - acc: 0.9446\n",
      "Epoch 3/5\n",
      "30000/30000 [==============================] - 9s 312us/sample - loss: 0.1298 - acc: 0.9585s - l\n",
      "Epoch 4/5\n",
      "30000/30000 [==============================] - 9s 297us/sample - loss: 0.1092 - acc: 0.9665\n",
      "Epoch 5/5\n",
      "30000/30000 [==============================] - 9s 296us/sample - loss: 0.0946 - acc: 0.9712\n",
      "30000/30000 [==============================] - 3s 111us/sample - loss: 0.0879 - acc: 0.9723\n",
      "Epoch 1/5\n",
      "30000/30000 [==============================] - 18s 608us/sample - loss: 0.6563 - acc: 0.8102\n",
      "Epoch 2/5\n",
      "30000/30000 [==============================] - 18s 615us/sample - loss: 0.2428 - acc: 0.9260\n",
      "Epoch 3/5\n",
      "30000/30000 [==============================] - 19s 624us/sample - loss: 0.1674 - acc: 0.9486\n",
      "Epoch 4/5\n",
      "30000/30000 [==============================] - 18s 585us/sample - loss: 0.1317 - acc: 0.9597\n",
      "Epoch 5/5\n",
      "30000/30000 [==============================] - 18s 587us/sample - loss: 0.1101 - acc: 0.9659\n",
      "30000/30000 [==============================] - 5s 162us/sample - loss: 0.1008 - acc: 0.9695\n",
      "Epoch 1/5\n",
      "30000/30000 [==============================] - 18s 612us/sample - loss: 0.6612 - acc: 0.8068\n",
      "Epoch 2/5\n",
      "30000/30000 [==============================] - 18s 599us/sample - loss: 0.2377 - acc: 0.9282\n",
      "Epoch 3/5\n",
      "30000/30000 [==============================] - 18s 591us/sample - loss: 0.1584 - acc: 0.9534\n",
      "Epoch 4/5\n",
      "30000/30000 [==============================] - 18s 591us/sample - loss: 0.1228 - acc: 0.9622\n",
      "Epoch 5/5\n",
      "30000/30000 [==============================] - 17s 575us/sample - loss: 0.0999 - acc: 0.9701\n",
      "30000/30000 [==============================] - 5s 157us/sample - loss: 0.0961 - acc: 0.9709\n",
      "Epoch 1/5\n",
      "30000/30000 [==============================] - 9s 317us/sample - loss: 1.0425 - acc: 0.6772\n",
      "Epoch 2/5\n",
      "30000/30000 [==============================] - 9s 297us/sample - loss: 0.3564 - acc: 0.8934ETA: 4 - ETA: 0s - loss: 0.363\n",
      "Epoch 3/5\n",
      "30000/30000 [==============================] - 9s 297us/sample - loss: 0.2485 - acc: 0.9262s - l - ETA: 6s - loss: 0.2734 - acc: 0.919 - ETA: 6s - loss: - ETA: 0s - loss: 0.2483 - acc: 0.92\n",
      "Epoch 4/5\n",
      "30000/30000 [==============================] - 9s 297us/sample - loss: 0.1984 - acc: 0.9396s - loss: 0.\n",
      "Epoch 5/5\n",
      "30000/30000 [==============================] - 9s 298us/sample - loss: 0.1723 - acc: 0.9465s - loss: 0\n",
      "30000/30000 [==============================] - 3s 110us/sample - loss: 0.1456 - acc: 0.9568\n",
      "Epoch 1/5\n",
      "30000/30000 [==============================] - 10s 318us/sample - loss: 1.0353 - acc: 0.6892\n",
      "Epoch 2/5\n",
      "30000/30000 [==============================] - 9s 295us/sample - loss: 0.3670 - acc: 0.8901s - loss: \n",
      "Epoch 3/5\n",
      "30000/30000 [==============================] - 9s 296us/sample - loss: 0.2587 - acc: 0.9224\n",
      "Epoch 4/5\n",
      "30000/30000 [==============================] - 9s 296us/sample - loss: 0.2069 - acc: 0.9371s - loss: 0.2071 - a\n",
      "Epoch 5/5\n",
      "30000/30000 [==============================] - 9s 314us/sample - loss: 0.1767 - acc: 0.9456\n",
      "30000/30000 [==============================] - 3s 111us/sample - loss: 0.1422 - acc: 0.9580\n",
      "Epoch 1/5\n",
      "30000/30000 [==============================] - 18s 610us/sample - loss: 1.9937 - acc: 0.3100\n",
      "Epoch 2/5\n",
      "30000/30000 [==============================] - 18s 595us/sample - loss: 0.5708 - acc: 0.8455\n",
      "Epoch 3/5\n",
      "30000/30000 [==============================] - 19s 627us/sample - loss: 0.3525 - acc: 0.8981\n",
      "Epoch 4/5\n",
      "30000/30000 [==============================] - 18s 605us/sample - loss: 0.2616 - acc: 0.9229\n",
      "Epoch 5/5\n",
      "30000/30000 [==============================] - 18s 611us/sample - loss: 0.2068 - acc: 0.9388\n",
      "30000/30000 [==============================] - 5s 169us/sample - loss: 0.1777 - acc: 0.9476\n",
      "Epoch 1/5\n",
      "30000/30000 [==============================] - 19s 622us/sample - loss: 1.8737 - acc: 0.3625\n",
      "Epoch 2/5\n",
      "30000/30000 [==============================] - 18s 589us/sample - loss: 0.5228 - acc: 0.8583\n",
      "Epoch 3/5\n",
      "30000/30000 [==============================] - 18s 595us/sample - loss: 0.3222 - acc: 0.9081\n",
      "Epoch 4/5\n",
      "30000/30000 [==============================] - 19s 620us/sample - loss: 0.2342 - acc: 0.9324\n",
      "Epoch 5/5\n",
      "30000/30000 [==============================] - 18s 596us/sample - loss: 0.1853 - acc: 0.9463\n",
      "30000/30000 [==============================] - 5s 168us/sample - loss: 0.1625 - acc: 0.9515s - loss: 0.1636\n",
      "Epoch 1/5\n",
      "30000/30000 [==============================] - 10s 350us/sample - loss: 2.3079 - acc: 0.1028\n",
      "Epoch 2/5\n",
      "30000/30000 [==============================] - 10s 327us/sample - loss: 2.2764 - acc: 0.1481\n",
      "Epoch 3/5\n",
      "30000/30000 [==============================] - 10s 325us/sample - loss: 1.8257 - acc: 0.4250\n",
      "Epoch 4/5\n",
      "30000/30000 [==============================] - 10s 337us/sample - loss: 1.2377 - acc: 0.6183\n",
      "Epoch 5/5\n",
      "30000/30000 [==============================] - 10s 342us/sample - loss: 0.9039 - acc: 0.7163\n",
      "30000/30000 [==============================] - 4s 120us/sample - loss: 0.7584 - acc: 0.7597\n",
      "Epoch 1/5\n",
      "30000/30000 [==============================] - 11s 354us/sample - loss: 2.3102 - acc: 0.1077\n",
      "Epoch 2/5\n",
      "30000/30000 [==============================] - 10s 325us/sample - loss: 2.1693 - acc: 0.2168\n",
      "Epoch 3/5\n",
      "30000/30000 [==============================] - 11s 356us/sample - loss: 1.6441 - acc: 0.4805\n",
      "Epoch 4/5\n",
      "30000/30000 [==============================] - 10s 346us/sample - loss: 1.1661 - acc: 0.6506\n",
      "Epoch 5/5\n",
      "30000/30000 [==============================] - 11s 356us/sample - loss: 0.8591 - acc: 0.7403\n",
      "30000/30000 [==============================] - 4s 120us/sample - loss: 0.7112 - acc: 0.7889s - loss: 0.7\n",
      "Epoch 1/5\n",
      "30000/30000 [==============================] - 19s 624us/sample - loss: 2.2905 - acc: 0.1380\n",
      "Epoch 2/5\n",
      "30000/30000 [==============================] - 20s 668us/sample - loss: 1.5766 - acc: 0.6078\n",
      "Epoch 3/5\n",
      "30000/30000 [==============================] - 19s 645us/sample - loss: 0.7485 - acc: 0.8087\n",
      "Epoch 4/5\n",
      "30000/30000 [==============================] - 20s 662us/sample - loss: 0.5463 - acc: 0.8495\n",
      "Epoch 5/5\n",
      "30000/30000 [==============================] - 19s 649us/sample - loss: 0.4518 - acc: 0.8735\n",
      "30000/30000 [==============================] - 5s 169us/sample - loss: 0.4096 - acc: 0.8800\n",
      "Epoch 1/5\n",
      "30000/30000 [==============================] - 19s 624us/sample - loss: 2.2984 - acc: 0.1282\n",
      "Epoch 2/5\n",
      "30000/30000 [==============================] - 20s 666us/sample - loss: 1.6924 - acc: 0.5627\n",
      "Epoch 3/5\n",
      "30000/30000 [==============================] - 19s 646us/sample - loss: 0.7939 - acc: 0.7932\n",
      "Epoch 4/5\n",
      "30000/30000 [==============================] - 20s 652us/sample - loss: 0.5638 - acc: 0.8462\n",
      "Epoch 5/5\n",
      "30000/30000 [==============================] - 19s 648us/sample - loss: 0.4597 - acc: 0.8710\n",
      "30000/30000 [==============================] - 5s 169us/sample - loss: 0.4000 - acc: 0.8835\n",
      "Epoch 1/5\n",
      "30000/30000 [==============================] - 11s 355us/sample - loss: 2.3113 - acc: 0.1064\n",
      "Epoch 2/5\n",
      "30000/30000 [==============================] - 10s 331us/sample - loss: 2.3025 - acc: 0.1084\n",
      "Epoch 3/5\n",
      "30000/30000 [==============================] - 11s 351us/sample - loss: 2.3009 - acc: 0.1152\n",
      "Epoch 4/5\n",
      "30000/30000 [==============================] - 10s 347us/sample - loss: 2.2883 - acc: 0.1496\n",
      "Epoch 5/5\n",
      "30000/30000 [==============================] - 10s 343us/sample - loss: 2.2208 - acc: 0.2170\n",
      "30000/30000 [==============================] - 4s 124us/sample - loss: 2.1364 - acc: 0.2898\n",
      "Epoch 1/5\n",
      "30000/30000 [==============================] - 11s 353us/sample - loss: 2.3066 - acc: 0.1098\n",
      "Epoch 2/5\n",
      "30000/30000 [==============================] - 12s 410us/sample - loss: 2.3007 - acc: 0.1169\n",
      "Epoch 3/5\n",
      "30000/30000 [==============================] - 13s 446us/sample - loss: 2.2942 - acc: 0.1272\n",
      "Epoch 4/5\n",
      "30000/30000 [==============================] - 13s 429us/sample - loss: 2.2551 - acc: 0.1797\n",
      "Epoch 5/5\n",
      "30000/30000 [==============================] - 15s 506us/sample - loss: 2.1076 - acc: 0.2801\n",
      "30000/30000 [==============================] - 5s 180us/sample - loss: 1.9906 - acc: 0.3497\n",
      "Epoch 1/5\n",
      "30000/30000 [==============================] - 25s 846us/sample - loss: 1.8573 - acc: 0.3818\n",
      "Epoch 2/5\n",
      "30000/30000 [==============================] - 24s 784us/sample - loss: 0.5107 - acc: 0.8614\n",
      "Epoch 3/5\n",
      "30000/30000 [==============================] - 26s 868us/sample - loss: 0.3109 - acc: 0.9111\n",
      "Epoch 4/5\n",
      "30000/30000 [==============================] - 24s 795us/sample - loss: 0.2295 - acc: 0.9329\n",
      "Epoch 5/5\n",
      "30000/30000 [==============================] - 25s 833us/sample - loss: 0.1807 - acc: 0.9465 - loss: 0.1828 - \n",
      "30000/30000 [==============================] - 6s 200us/sample - loss: 0.1583 - acc: 0.9532\n",
      "Epoch 1/5\n",
      "30000/30000 [==============================] - 28s 940us/sample - loss: 2.1392 - acc: 0.2617 - loss: 2.1443 - acc: 0.259\n",
      "Epoch 2/5\n",
      "30000/30000 [==============================] - 23s 761us/sample - loss: 0.7536 - acc: 0.8104\n",
      "Epoch 3/5\n",
      "30000/30000 [==============================] - 23s 773us/sample - loss: 0.4137 - acc: 0.8864 -\n",
      "Epoch 4/5\n",
      "30000/30000 [==============================] - 22s 720us/sample - loss: 0.2972 - acc: 0.9146\n",
      "Epoch 5/5\n",
      "30000/30000 [==============================] - 23s 769us/sample - loss: 0.2249 - acc: 0.9343\n",
      "30000/30000 [==============================] - 5s 181us/sample - loss: 0.1920 - acc: 0.9435\n",
      "Epoch 1/5\n",
      "30000/30000 [==============================] - 11s 353us/sample - loss: 2.2605 - acc: 0.1841\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 11s 378us/sample - loss: 1.4101 - acc: 0.6742\n",
      "Epoch 3/5\n",
      "30000/30000 [==============================] - 11s 375us/sample - loss: 0.6229 - acc: 0.8614\n",
      "Epoch 4/5\n",
      "30000/30000 [==============================] - 10s 349us/sample - loss: 0.3661 - acc: 0.9104\n",
      "Epoch 5/5\n",
      "30000/30000 [==============================] - 11s 351us/sample - loss: 0.2789 - acc: 0.9232\n",
      "30000/30000 [==============================] - 4s 121us/sample - loss: 0.2356 - acc: 0.9331\n",
      "Epoch 1/5\n",
      "30000/30000 [==============================] - 12s 396us/sample - loss: 2.2037 - acc: 0.2374\n",
      "Epoch 2/5\n",
      "30000/30000 [==============================] - 12s 384us/sample - loss: 1.0876 - acc: 0.7596\n",
      "Epoch 3/5\n",
      "30000/30000 [==============================] - 12s 393us/sample - loss: 0.4903 - acc: 0.8838\n",
      "Epoch 4/5\n",
      "30000/30000 [==============================] - 13s 418us/sample - loss: 0.3229 - acc: 0.9136\n",
      "Epoch 5/5\n",
      "30000/30000 [==============================] - 11s 372us/sample - loss: 0.2543 - acc: 0.9278\n",
      "30000/30000 [==============================] - 4s 140us/sample - loss: 0.1984 - acc: 0.9446\n",
      "Epoch 1/5\n",
      "30000/30000 [==============================] - 21s 697us/sample - loss: 2.2464 - acc: 0.2102\n",
      "Epoch 2/5\n",
      "30000/30000 [==============================] - 20s 678us/sample - loss: 1.2585 - acc: 0.7086\n",
      "Epoch 3/5\n",
      "30000/30000 [==============================] - 19s 627us/sample - loss: 0.6774 - acc: 0.8223\n",
      "Epoch 4/5\n",
      "30000/30000 [==============================] - 18s 610us/sample - loss: 0.4867 - acc: 0.8690\n",
      "Epoch 5/5\n",
      "30000/30000 [==============================] - 18s 602us/sample - loss: 0.3837 - acc: 0.8941\n",
      "30000/30000 [==============================] - 5s 170us/sample - loss: 0.3446 - acc: 0.9048\n",
      "Epoch 1/5\n",
      "30000/30000 [==============================] - 20s 659us/sample - loss: 2.2766 - acc: 0.1717\n",
      "Epoch 2/5\n",
      "30000/30000 [==============================] - 19s 633us/sample - loss: 1.4400 - acc: 0.6583\n",
      "Epoch 3/5\n",
      "30000/30000 [==============================] - 19s 632us/sample - loss: 0.7162 - acc: 0.8177\n",
      "Epoch 4/5\n",
      "30000/30000 [==============================] - 21s 687us/sample - loss: 0.5139 - acc: 0.8633\n",
      "Epoch 5/5\n",
      "30000/30000 [==============================] - 19s 649us/sample - loss: 0.4066 - acc: 0.8876\n",
      "30000/30000 [==============================] - 6s 188us/sample - loss: 0.3533 - acc: 0.9018\n",
      "Epoch 1/5\n",
      "30000/30000 [==============================] - 11s 359us/sample - loss: 2.2975 - acc: 0.1301\n",
      "Epoch 2/5\n",
      "30000/30000 [==============================] - 10s 334us/sample - loss: 2.1573 - acc: 0.3473\n",
      "Epoch 3/5\n",
      "30000/30000 [==============================] - 10s 335us/sample - loss: 1.7344 - acc: 0.5449\n",
      "Epoch 4/5\n",
      "30000/30000 [==============================] - 10s 326us/sample - loss: 1.2639 - acc: 0.6945\n",
      "Epoch 5/5\n",
      "30000/30000 [==============================] - 10s 326us/sample - loss: 0.9445 - acc: 0.7745\n",
      "30000/30000 [==============================] - 4s 124us/sample - loss: 0.8009 - acc: 0.8051\n",
      "Epoch 1/5\n",
      "30000/30000 [==============================] - 11s 363us/sample - loss: 2.2989 - acc: 0.1120\n",
      "Epoch 2/5\n",
      "30000/30000 [==============================] - 10s 338us/sample - loss: 2.1553 - acc: 0.3431\n",
      "Epoch 3/5\n",
      "30000/30000 [==============================] - 10s 334us/sample - loss: 1.7124 - acc: 0.5455\n",
      "Epoch 4/5\n",
      "30000/30000 [==============================] - 10s 326us/sample - loss: 1.2669 - acc: 0.6681\n",
      "Epoch 5/5\n",
      "30000/30000 [==============================] - 10s 326us/sample - loss: 0.9646 - acc: 0.7433\n",
      "30000/30000 [==============================] - 4s 126us/sample - loss: 0.8188 - acc: 0.7917\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 39s 646us/sample - loss: 0.3076 - acc: 0.9075\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 37s 618us/sample - loss: 0.0886 - acc: 0.9725\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 37s 611us/sample - loss: 0.0658 - acc: 0.9787\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 37s 617us/sample - loss: 0.0522 - acc: 0.9837\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 39s 647us/sample - loss: 0.0435 - acc: 0.9865\n",
      "Best Accuracy for 0.9781 using {'activation': 'relu', 'kernel_size': 6, 'optimizer': 'Adam', 'pool_size': 2}\n"
     ]
    }
   ],
   "source": [
    "#Hyperparameter Tuning\n",
    "\n",
    "def recognition_model(activation='relu', kernel_size=4, pool_size=2, optimizer='Adam'):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=kernel_size, input_shape=(28,28,1), activation=activation))\n",
    "    model.add(MaxPooling2D(pool_size=pool_size, padding='same'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv2D(32, kernel_size=kernel_size, input_shape=(28,28,1), activation=activation))\n",
    "    model.add(MaxPooling2D(pool_size=pool_size, padding='same'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation=activation))\n",
    "    model.add(Dense(classes_count, activation='softmax'))\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "batch_size = 200\n",
    "epochs = 5\n",
    "model_cv = KerasClassifier(build_fn=recognition_model, batch_size=batch_size, epochs=epochs, verbose=1)\n",
    "\n",
    "\n",
    "activation = ['relu', 'sigmoid']\n",
    "optimizer = ['Adam', 'Adamax']\n",
    "kernel_size = [4, 6]\n",
    "pool_size = [2, 4]\n",
    "param_grid=dict(activation=activation, optimizer=optimizer, kernel_size=kernel_size, pool_size=pool_size)\n",
    "grid = GridSearchCV(estimator=model_cv, param_grid=param_grid, cv=2)\n",
    "\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "print(f'Best Accuracy for {grid_result.best_score_:.4} using {grid_result.best_params_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
